{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3cf8aa-ed91-4745-aed3-cce54903031b",
   "metadata": {},
   "source": [
    "### Import Excel Files To SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a072784c-3f11-406d-9a21-958a468a8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "# ---------- SQL Server connection details ----------\n",
    "server = 'AG-SERVER-043'         # e.g. 'localhost\\SQLEXPRESS'\n",
    "database = 'harsh_data'\n",
    "username = 'data05'\n",
    "password = 'sai@123'\n",
    "\n",
    "# ---------- Create the SQLAlchemy engine ----------\n",
    "params = urllib.parse.quote_plus(\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"UID={username};PWD={password}\"\n",
    ")\n",
    "\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "# ---------- Folder path to start looking for Excel files ----------\n",
    "#root_folder = r\"E:\\Back-Up Files\\Data Team\\Position & M2M\\Intraday files\"\n",
    "root_folder = r\"E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\"\n",
    "# ---------- Loop through folders and process Excel files ----------\n",
    "for dirpath, _, filenames in os.walk(root_folder):\n",
    "    for file in filenames:\n",
    "        if file.lower().endswith('.xlsx'):\n",
    "            file_path = os.path.join(dirpath, file)\n",
    "            table_name = os.path.splitext(file)[0].replace(' ', '_').replace('-', '_')\n",
    "\n",
    "            print(f\"\\nüì• Importing: {file_path} ‚Üí Table: {table_name}\")\n",
    "\n",
    "            try:\n",
    "                # Read the first sheet of the Excel file\n",
    "                df = pd.read_excel(file_path)\n",
    "\n",
    "                # Upload to SQL Server (replace table if exists)\n",
    "                df.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "                print(f\"‚úÖ Successfully imported into table: {table_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to import {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa192bb-4880-40df-b214-637f8ffd634e",
   "metadata": {},
   "source": [
    "### Export SQL Files To Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec97f526-acc0-48a9-8172-e2b3c84d6db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì§ Exporting table: EXP_ALLOVER_June_2_NET_\n",
      "‚úÖ Exported to: E:\\Back-Up Files\\Data Team\\Position & M2M\\NET FILES 2025\\EXP_ALLOVER_June_2_NET_.xlsx\n",
      "\n",
      "üì§ Exporting table: EXP_ALLOVER_June_3_NET_\n",
      "‚úÖ Exported to: E:\\Back-Up Files\\Data Team\\Position & M2M\\NET FILES 2025\\EXP_ALLOVER_June_3_NET_.xlsx\n",
      "\n",
      "üì§ Exporting table: EXP_ALLOVER_June_4_NET_\n",
      "‚úÖ Exported to: E:\\Back-Up Files\\Data Team\\Position & M2M\\NET FILES 2025\\EXP_ALLOVER_June_4_NET_.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import urllib\n",
    "\n",
    "# ---------- SQL Server connection details ----------\n",
    "server = 'AG-SERVER-043'\n",
    "database = 'harsh_data'\n",
    "username = 'data05'\n",
    "password = 'sai@123'\n",
    "\n",
    "# ---------- Output folder for Excel files ----------\n",
    "output_folder = r\"E:\\Back-Up Files\\Data Team\\Position & M2M\\NET FILES 2025\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ---------- Create the SQLAlchemy engine ----------\n",
    "params = urllib.parse.quote_plus(\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"UID={username};PWD={password}\"\n",
    ")\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "# ---------- Define table name pattern ----------\n",
    "prefix = 'EXP_ALLOVER_June_'\n",
    "suffix = '_NET_'\n",
    "\n",
    "# ---------- Fetch table names ----------\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"\"\"\n",
    "        SELECT TABLE_NAME \n",
    "        FROM INFORMATION_SCHEMA.TABLES \n",
    "        WHERE TABLE_TYPE = 'BASE TABLE'\n",
    "    \"\"\"))\n",
    "    all_tables = [row[0] for row in result]\n",
    "\n",
    "# ---------- Filter tables matching the pattern ----------\n",
    "april_tables = [tbl for tbl in all_tables if tbl.startswith(prefix) and tbl.endswith(suffix)]\n",
    "\n",
    "# ---------- Export each matched table to Excel ----------\n",
    "for table_name in april_tables:\n",
    "    try:\n",
    "        print(f\"\\nüì§ Exporting table: {table_name}\")\n",
    "        df = pd.read_sql(f\"SELECT * FROM [{table_name}]\", con=engine)\n",
    "        \n",
    "        file_path = os.path.join(output_folder, f\"{table_name}.xlsx\")\n",
    "        df.to_excel(file_path, index=False)\n",
    "        print(f\"‚úÖ Exported to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to export {table_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90856b-29f8-49a5-87c5-192daf1001e5",
   "metadata": {},
   "source": [
    "### CSV import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349838aa-c0ff-4765-95b0-daa9f7e84fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_22_CM.csv ‚Üí Table: BHAVCOPY_2025_01_22_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_22_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_23_CM.csv ‚Üí Table: BHAVCOPY_2025_01_23_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_23_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_24_CM.csv ‚Üí Table: BHAVCOPY_2025_01_24_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_24_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_27_CM.csv ‚Üí Table: BHAVCOPY_2025_01_27_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_27_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_28_CM.csv ‚Üí Table: BHAVCOPY_2025_01_28_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_28_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_29_CM.csv ‚Üí Table: BHAVCOPY_2025_01_29_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_29_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_30_CM.csv ‚Üí Table: BHAVCOPY_2025_01_30_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_30_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\JAN MERGE\\BHAVCOPY_2025_01_31_CM.csv ‚Üí Table: BHAVCOPY_2025_01_31_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_31_CM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "# ---------- SQL Server connection details ----------\n",
    "server = 'AG-SERVER-043'\n",
    "database = 'harsh_data'\n",
    "username = 'data05'\n",
    "password = 'sai@123'\n",
    "\n",
    "# ---------- Create the SQLAlchemy engine ----------\n",
    "params = urllib.parse.quote_plus(\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"UID={username};PWD={password}\"\n",
    ")\n",
    "\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "# ---------- Folder path to start looking for CSV files ----------\n",
    "root_folder = r\"E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\FEB_2025_CM - Copy\"\n",
    "\n",
    "# ---------- Loop through folders and process CSV files ----------\n",
    "for dirpath, _, filenames in os.walk(root_folder):\n",
    "    for file in filenames:\n",
    "        if file.lower().endswith('.csv'):\n",
    "            file_path = os.path.join(dirpath, file)\n",
    "            table_name = os.path.splitext(file)[0].replace(' ', '_').replace('-', '_')\n",
    "\n",
    "            print(f\"\\nüì• Importing: {file_path} ‚Üí Table: {table_name}\")\n",
    "\n",
    "            try:\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "\n",
    "                # Upload to SQL Server (replace table if it exists)\n",
    "                df.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "                print(f\"‚úÖ Successfully imported into table: {table_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to import {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d98b88d-0159-4151-853c-156bc8d1fdde",
   "metadata": {},
   "source": [
    "#### BHAVCOPY IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5ffd18-ac44-4bc4-88c7-46a8f5558156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\Uoload_CM\\BHAVCOPY_2025_01_23_CM.csv ‚Üí Table: BHAVCOPY_2025_01_23_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_23_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\Uoload_CM\\BHAVCOPY_2025_01_24_CM.csv ‚Üí Table: BHAVCOPY_2025_01_24_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_24_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\Uoload_CM\\BHAVCOPY_2025_01_27_CM.csv ‚Üí Table: BHAVCOPY_2025_01_27_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_27_CM\n",
      "\n",
      "üì• Importing: E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\Uoload_CM\\BHAVCOPY_2025_01_28_CM.csv ‚Üí Table: BHAVCOPY_2025_01_28_CM\n",
      "‚úÖ Successfully imported into table: BHAVCOPY_2025_01_28_CM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import urllib\n",
    "\n",
    "# ---------- SQL Server connection details ----------\n",
    "server = 'AG-SERVER-043'\n",
    "database = 'harsh_data'\n",
    "username = 'data05'\n",
    "password = 'sai@123'\n",
    "\n",
    "# ---------- Create the SQLAlchemy engine ----------\n",
    "params = urllib.parse.quote_plus(\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"UID={username};PWD={password}\"\n",
    ")\n",
    "\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "# ---------- Folder path to start looking for CSV files ----------\n",
    "root_folder = r\"E:\\Back-Up Files\\Data Team\\BSE - NSE\\Bhavcopy_CM(MERGED)\\Uoload_CM\"\n",
    "\n",
    "# ---------- Create an inspector to check existing tables ----------\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# ---------- Loop through folders and process CSV files ----------\n",
    "for dirpath, _, filenames in os.walk(root_folder):\n",
    "    for file in filenames:\n",
    "        if file.lower().endswith('.csv'):\n",
    "            file_path = os.path.join(dirpath, file)\n",
    "            table_name = os.path.splitext(file)[0].replace(' ', '_').replace('-', '_')\n",
    "\n",
    "            # Check if table already exists\n",
    "            if table_name in inspector.get_table_names():\n",
    "                print(f\"‚è≠Ô∏è Skipping {file} ‚Üí Table '{table_name}' already exists.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nüì• Importing: {file_path} ‚Üí Table: {table_name}\")\n",
    "\n",
    "            try:\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(file_path, low_memory = False)\n",
    "\n",
    "                # Upload to SQL Server (fail if table already exists)\n",
    "                df.to_sql(name=table_name, con=engine, if_exists='fail', index=False)\n",
    "                print(f\"‚úÖ Successfully imported into table: {table_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to import {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5687ee7-5d4d-4d2c-90e0-040911a674ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0972dcd-2de1-4319-9cfd-2100246ebc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
