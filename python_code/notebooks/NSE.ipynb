{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e48cf-2f22-426a-a3f0-2f6a92c18838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE CONVERSION #####111111111111111111111111111111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1ca432-b7ba-4b03-a716-738b77feae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11483035616472333037_YASH.xls: Pandas requires version '2.0.1' or newer of 'xlrd' (version '1.2.0' currently installed).\n",
      "Converted E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11483035616472333037_YASH.xls to E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11483035616472333037_YASH.csv as HTML\n",
      "Failed to convert E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11555133703915625182_YASH.xls: Pandas requires version '2.0.1' or newer of 'xlrd' (version '1.2.0' currently installed).\n",
      "Converted E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11555133703915625182_YASH.xls to E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11555133703915625182_YASH.csv as HTML\n",
      "Failed to convert E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11581336251438557051_YASH.xls: Pandas requires version '2.0.1' or newer of 'xlrd' (version '1.2.0' currently installed).\n",
      "Converted E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11581336251438557051_YASH.xls to E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11581336251438557051_YASH.csv as HTML\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11483035616472333037_YASH.csv\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11555133703915625182_YASH.csv\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\DAYWISE_890_19062025_11581336251438557051_YASH.csv\n",
      "All CSV files have been merged into 'E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\19062025.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert files (.xls, .xlsx, .html) to CSV\n",
    "def convert_file_to_csv(file_path, csv_file_path):\n",
    "    try:\n",
    "        # Attempt to read the file as an Excel file, skipping the first two rows\n",
    "        if file_path.endswith('.xls') or file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, engine='openpyxl' if file_path.endswith('.xlsx') else 'xlrd', skiprows=2)\n",
    "        else:\n",
    "            # If it's a CSV, skip the first two rows\n",
    "            df = pd.read_csv(file_path, skiprows=2)  # Skip the first 2 rows for CSV files\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Converted {file_path} to {csv_file_path} as Excel or CSV\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {file_path}: {e}\")\n",
    "        \n",
    "        # Try reading as an HTML file if it contains web page data\n",
    "        try:\n",
    "            df = pd.read_html(file_path)[0]  # Read the first table\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Converted {file_path} to {csv_file_path} as HTML\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file_path} as HTML: {e}\")\n",
    "\n",
    "# Function to recursively search for files (.xls, .xlsx, .html) and convert them to CSV\n",
    "def convert_files_to_csv(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check for .xls, .xlsx, .html extensions\n",
    "            if file.endswith('.xls') or file.endswith('.xlsx') or file.endswith('.html') or file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                csv_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.csv\")\n",
    "                \n",
    "                # Convert the file to CSV\n",
    "                convert_file_to_csv(file_path, csv_file_path)\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Function to recursively search for CSV files and merge them\n",
    "def merge_csv_files(directory):\n",
    "    global merged_df\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV file (case insensitive)\n",
    "            if file.lower().endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read the CSV file into a DataFrame, skipping the first two rows\n",
    "                    df = pd.read_csv(file_path, skiprows=2)  # Skipping the first 2 rows when reading CSV files\n",
    "                    if not df.empty:\n",
    "                        # Append the DataFrame to the merged DataFrame\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "                        print(f'Merged: {file_path}')\n",
    "                    else:\n",
    "                        print(f'Skipped empty file: {file_path}')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f'Skipped file with empty data: {file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing file {file_path}: {e}')\n",
    "\n",
    "# Function to perform the entire process of conversion and merging\n",
    "def convert_and_merge_files(folder_path):\n",
    "    # Convert all relevant files (.xls, .xlsx, .html) to CSV\n",
    "    convert_files_to_csv(folder_path)\n",
    "    \n",
    "    # Merge all CSV files found in the folder\n",
    "    merge_csv_files(folder_path)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    output_file_path = os.path.join(folder_path, '19062025.csv')\n",
    "    merged_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"All CSV files have been merged into '{output_file_path}'\")\n",
    "\n",
    "# Define the folder path (use raw string to avoid issues with backslashes)\n",
    "folder_path = r'E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File'  # Update with your folder path\n",
    "\n",
    "# Perform the conversion and merging process\n",
    "convert_and_merge_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc1f7f-3b2c-46e8-9956-deb6040476f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COMBINE WITH DATE ND ALL ########22222222222222222222222222222222222                          ####Name Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cce505a-bd57-4865-88c3-c5d00268af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_files(folder_path):\n",
    "    all_data = []  # List to hold all dataframes\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Extract the date from the filename (remove the .csv extension)\n",
    "                date_value = file[:-4]  # e.g., '01042024'\n",
    "                \n",
    "                # Convert to datetime using the correct format (DDMMYYYY)\n",
    "                formatted_date = pd.to_datetime(date_value, format='%d%m%Y').strftime('%d-%m-%Y')\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read the CSV file (without skipping any rows)\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Add the TradeDate column with the formatted date\n",
    "                df['TradeDate'] = formatted_date\n",
    "                \n",
    "                # Append the modified DataFrame to the list\n",
    "                all_data.append(df)\n",
    "\n",
    "    # Combine all dataframes into one\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a new CSV file \n",
    "    combined_df.to_csv(os.path.join(folder_path, '19.csv'), index=False)\n",
    "\n",
    "# Specify the path to your main folder\n",
    "main_folder = r'E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File'  # or use forward slashes\n",
    "process_csv_files(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd0703-4200-4101-94e3-81022640391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FORMATE  ##########3333333333333333333333333333333                        ####Name Change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8e56b5-2bd9-4678-b930-8883b06af172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'TradeDate': object\n",
      "Updated DataFrame:\n",
      "   CLIENT_ID COMPANY_CODE                 SCRIP_SYMBOL  NET_QUANTITY  NET_RATE  \\\n",
      "0  NFTOPT01  DERIVATIVES  NIFTY 19Jun25 CE 24800.0000             0    0.0000   \n",
      "1  NFTOPT01  DERIVATIVES  NIFTY 19Jun25 PE 24800.0000             0    0.0000   \n",
      "2  NFTOPT01  DERIVATIVES  NIFTY 26Jun25 CE 24900.0000          3975  150.8292   \n",
      "3  NFTOPT01  DERIVATIVES  NIFTY 26Jun25 PE 24900.0000         -3975  222.1981   \n",
      "4  NFTOPT01     EXPENSES                *SERVICE TAX*             0    0.0000   \n",
      "\n",
      "   NET_AMOUNT  CLOSING_PRICE  NOT_PROFIT  TRADING_QUANTITY  TRADING_AMOUNT  \\\n",
      "0    59366.25           0.00    59366.25             -1950            81.9   \n",
      "1   -39727.50           0.00   -39727.50              1950            82.1   \n",
      "2  -599546.25         142.05   -34897.50                 0             0.0   \n",
      "3   883237.50         237.60   -61222.50                 0             0.0   \n",
      "4     -147.63           0.00     -147.63                 0             0.0   \n",
      "\n",
      "   BUY_QUANTITY  BUY_RATE  BUY_AMOUNT  SALE_QUANTITY  SALE_RATE  SALE_AMOUNT  \\\n",
      "0          1950     51.46      100339              0       0.00            0   \n",
      "1             0      0.00           0           1950      61.73       120368   \n",
      "2          4125    150.81      622076            150     150.20        22530   \n",
      "3           150    222.43       33364           4125     222.21       916601   \n",
      "4             0      0.00         148              0       0.00            0   \n",
      "\n",
      "   TradeDate  \n",
      "0 2025-06-19  \n",
      "1 2025-06-19  \n",
      "2 2025-06-19  \n",
      "3 2025-06-19  \n",
      "4 2025-06-19  \n",
      "The date format has been updated and saved back to the same file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(r'E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\19.csv')\n",
    "\n",
    "# Check the data type of 'TradeDate'\n",
    "print(\"Data type of 'TradeDate':\", df['TradeDate'].dtype)\n",
    "\n",
    "# If 'TradeDate' is not a string, convert it to string first\n",
    "if not pd.api.types.is_string_dtype(df['TradeDate']):\n",
    "    df['TradeDate'] = df['TradeDate'].astype(str)\n",
    "\n",
    "# Now convert 'TradeDate' to datetime format\n",
    "try:\n",
    "    df['TradeDate'] = pd.to_datetime(df['TradeDate'].str.replace('/', '-'), format='%d-%m-%Y')\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Display the updated DataFrame (optional, you can remove this if not needed)\n",
    "print(\"Updated DataFrame:\\n\", df.head())\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV fil\n",
    "df.to_csv(r'E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\Current Date File\\19.csv', index=False)\n",
    "\n",
    "print(\"The date format has been updated and saved back to the same file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68e226-109d-44be-b1bb-003433a484b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLUB   ####################444444444444444444444444444444444                ####Name Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931d7151-700a-479f-bbd9-8177bc1a828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\CLUB\\19.csv\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\CLUB\\25_Club18.csv\n",
      "All CSV files have been merged into 'E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\CLUB\\25_Club19.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# Path to the main folder\n",
    "main_folder_path = r'E:\\Back-Up Files\\Data Team\\2024-2025\\Process NSE\\CLUB'  # Use raw string literal to handle backslashes\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame() \n",
    "\n",
    "# Function to recursively search for CSV files and merge them\n",
    "def merge_csv_files(directory):\n",
    "    global merged_df\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV file (case insensitive)\n",
    "            if file.lower().endswith('.csv'):\n",
    "                # Construct the full path to the CSV file\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    if not df.empty:  # Check if DataFrame is not empty\n",
    "                        # Append the DataFrame to the merged DataFrame\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "                        print(f'Merged: {file_path}')  # Optional: print each file being merged\n",
    "                    else:\n",
    "                        print(f'Skipped empty file: {file_path}')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f'Skipped file with empty data: {file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing file {file_path}: {e}') \n",
    "\n",
    "\n",
    "\n",
    "# Call the function to start merging CSV files\n",
    "merge_csv_files(main_folder_path) \n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_file_path = os.path.join(main_folder_path, '25_Club19.csv')\n",
    "merged_df.to_csv(output_file_path, index=False) \n",
    "\n",
    "print(f\"All CSV files have been merged into '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646f412-3a09-48d0-9e77-a7227581d4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
