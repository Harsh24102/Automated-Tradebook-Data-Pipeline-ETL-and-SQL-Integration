{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3275d9-8236-46fb-a2bb-6eda67173bce",
   "metadata": {},
   "source": [
    "### For Cumulative files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2df907-2c04-436a-80f1-3de44c12d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert F:\\DATA TEAM\\Process MCX\\Cumulative File Process\\16012025 MCX.xls as Excel: Unsupported format, or corrupt file: Expected BOF record; found b'\\r\\n\\r\\n<TAB'\n",
      "Converted F:\\DATA TEAM\\Process MCX\\Cumulative File Process\\16012025 MCX.xls to F:\\DATA TEAM\\Process MCX\\Cumulative File Process\\16012025 MCX.csv as HTML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def convert_file_to_csv(file_path, csv_file_path):\n",
    "    try:\n",
    "        # Attempt to read the file as an Excel file\n",
    "        if file_path.endswith('.xls') or file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, engine='openpyxl' if file_path.endswith('.xlsx') else 'xlrd')\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, sep='\\t')  # In case it's tab-separated\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Converted {file_path} to {csv_file_path} as Excel\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {file_path} as Excel: {e}\")\n",
    "        \n",
    "        # Try reading as an HTML file if it contains web page data\n",
    "        try:\n",
    "            df = pd.read_html(file_path)[0]  # Read the first table\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Converted {file_path} to {csv_file_path} as HTML\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file_path} as HTML: {e}\")\n",
    "\n",
    "def convert_excel_to_csv(folder_path):\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check for Excel file extensions\n",
    "            if file.endswith('.xls') or file.endswith('.xlsx') or file.endswith('.html'):\n",
    "                # Define the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Define the CSV file path\n",
    "                csv_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.csv\")\n",
    "                \n",
    "                # Attempt conversion\n",
    "                convert_file_to_csv(file_path, csv_file_path)\n",
    "\n",
    "# Use a raw string for the folder path\n",
    "folder_path = r'F:\\DATA TEAM\\Process MCX\\Cumulative File Process'  # Change this to your folder path\n",
    "convert_excel_to_csv(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa45e59-9ef3-4e44-bc95-1faeb1379643",
   "metadata": {},
   "outputs": [],
   "source": [
    "###import os\n",
    "import pandas as pd\n",
    "\n",
    "def remove_first_two_rows(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Read the CSV file, skipping the first two rows\n",
    "                df = pd.read_csv(file_path, skiprows=2)\n",
    "                # Save the updated DataFrame back to the CSV\n",
    "                df.to_csv(file_path, index=False)\n",
    "\n",
    "# Specify the path to your main folder\n",
    "main_folder = r'F:\\DATA TEAM\\Process MCX\\Cumulative File Process'\n",
    "remove_first_two_rows(main_folder)###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe86a00-c8bf-435b-ba1b-f20002f00f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_files(folder_path):\n",
    "    # Loop through all files in the folder\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Extract the date from the filename by removing non-date portions\n",
    "                # For example, from '09072024 MCX.csv', we only need '09072024'\n",
    "                date_value = ''.join(filter(str.isdigit, file))[:8]  # e.g., '09072024'\n",
    "                \n",
    "                # Convert to datetime using the correct format (DDMMYYYY)\n",
    "                date_obj = pd.to_datetime(date_value, format='%d%m%Y')\n",
    "                \n",
    "                # Manually format the date to remove leading zeros\n",
    "                formatted_date = f\"{date_obj.day}/{date_obj.month}/{date_obj.year}\"\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read the CSV file, skipping the first two rows\n",
    "                df = pd.read_csv(file_path, skiprows=2)\n",
    "                \n",
    "                # Add the TradeDate column with the formatted date\n",
    "                df['TradeDate'] = formatted_date\n",
    "                \n",
    "                # Convert 'TradeDate' column to datetime format (DD/MM/YYYY)\n",
    "                df['TradeDate'] = pd.to_datetime(df['TradeDate'], format='%d/%m/%Y')\n",
    "                \n",
    "                # Save the modified DataFrame back to the same file\n",
    "                df.to_csv(file_path, index=False)\n",
    "\n",
    "# Specify the path to your main folder\n",
    "main_folder = r'F:\\DATA TEAM\\Process MCX\\Cumulative File Process'  # or use forward slashes\n",
    "process_csv_files(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237efdf-faee-40c8-9739-e4c29a555e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83bdfa4-c3e2-4edd-8daa-76e712d48fd3",
   "metadata": {},
   "source": [
    "### For Daily Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97156f51-d4a4-4d01-8973-a05f981c79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert F:\\DATA TEAM\\Process MCX\\Daywise File Process\\Current date file\\16012025.xls as Excel: Unsupported format, or corrupt file: Expected BOF record; found b'\\r\\n\\r\\n<TAB'\n",
      "Converted F:\\DATA TEAM\\Process MCX\\Daywise File Process\\Current date file\\16012025.xls to F:\\DATA TEAM\\Process MCX\\Daywise File Process\\Current date file\\16012025.csv as HTML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def convert_file_to_csv(file_path, csv_file_path):\n",
    "    try:\n",
    "        # Attempt to read the file as an Excel file\n",
    "        if file_path.endswith('.xls') or file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, engine='openpyxl' if file_path.endswith('.xlsx') else 'xlrd')\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, sep='\\t')  # In case it's tab-separated\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Converted {file_path} to {csv_file_path} as Excel\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {file_path} as Excel: {e}\")\n",
    "        \n",
    "        # Try reading as an HTML file if it contains web page data\n",
    "        try:\n",
    "            df = pd.read_html(file_path)[0]  # Read the first table\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Converted {file_path} to {csv_file_path} as HTML\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file_path} as HTML: {e}\")\n",
    "\n",
    "def convert_excel_to_csv(folder_path):\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check for Excel file extensions\n",
    "            if file.endswith('.xls') or file.endswith('.xlsx') or file.endswith('.html'):\n",
    "                # Define the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Define the CSV file path\n",
    "                csv_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.csv\")\n",
    "                \n",
    "                # Attempt conversion\n",
    "                convert_file_to_csv(file_path, csv_file_path)\n",
    "\n",
    "# Use a raw string for the folder path\n",
    "folder_path = r'F:\\DATA TEAM\\Process MCX\\Daywise File Process'  # Change this to your folder path\n",
    "convert_excel_to_csv(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88206533-3904-496f-847d-24b0dd204705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_files(folder_path):\n",
    "    all_data = []  # List to hold all dataframes\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Extract the date from the filename (remove the .csv extension)\n",
    "                date_value = file[:-4]  # e.g., '01042024'\n",
    "                \n",
    "                # Convert to datetime using the correct format (DDMMYYYY)\n",
    "                formatted_date = pd.to_datetime(date_value, format='%d%m%Y').strftime('%d-%m-%Y')\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read the CSV file, skipping the first two rows\n",
    "                df = pd.read_csv(file_path, skiprows=2)\n",
    "                \n",
    "                # Add the TradeDate column with the formatted date\n",
    "                df['TradeDate'] = formatted_date\n",
    "                \n",
    "                # Append the modified DataFrame to the list\n",
    "                all_data.append(df)\n",
    "\n",
    "    # Combine all dataframes into one\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a new CSV file \n",
    "    combined_df.to_csv(os.path.join(folder_path, '16.csv'), index=False)\n",
    "\n",
    "# Specify the path to your main folder\n",
    "main_folder = r'F:\\DATA TEAM\\Process MCX\\Daywise File Process\\Current date file'  # or use forward slashes\n",
    "process_csv_files(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08413764-50e5-4b64-b436-e5a123c1f8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'TradeDate': object\n",
      "Updated DataFrame:\n",
      "    CLIENT_ID COMPANY_CODE                   SCRIP_SYMBOL  NET_QUANTITY  \\\n",
      "0  MCXVIVA18    COMMODITY                  SILVER 5Mar25          -227   \n",
      "1  MCXVIVA28    COMMODITY  CRUDEOIL 17Feb25 CE 6800.0000            88   \n",
      "2  MCXVIVA28    COMMODITY  CRUDEOIL 17Feb25 PE 6800.0000           -88   \n",
      "3  MCXVIVA28    COMMODITY   NATURALG 24Jan25 CE 350.0000           272   \n",
      "4  MCXVIVA28    COMMODITY   NATURALG 24Jan25 CE 360.0000            34   \n",
      "\n",
      "     NET_RATE   NET_AMOUNT  CLOSING_PRICE  NOT_PROFIT  TRADING_QUANTITY  \\\n",
      "0  92856.0000  632349360.0       92803.00    360930.0              -227   \n",
      "1    324.1500   -2852520.0         237.20   -765160.0               352   \n",
      "2    193.0318    1698680.0         269.70   -674680.0              -352   \n",
      "3     21.8145   -7416937.5          22.85    352062.5               204   \n",
      "4     23.9912   -1019625.0          18.75   -222750.0                 0   \n",
      "\n",
      "   TRADING_AMOUNT  BUY_QUANTITY  BUY_RATE  BUY_AMOUNT  SALE_QUANTITY  \\\n",
      "0         92856.0             0      0.00           0              0   \n",
      "1           251.3             0      0.00           0            264   \n",
      "2           256.2           264    277.26     7319560              0   \n",
      "3            20.6           127     23.09     3664938             59   \n",
      "4             0.0            51     22.37     1426375             17   \n",
      "\n",
      "   SALE_RATE  SALE_AMOUNT  TradeDate  \n",
      "0       0.00            0 2025-01-16  \n",
      "1     227.02      5993240 2025-01-16  \n",
      "2       0.00            0 2025-01-16  \n",
      "3      20.35      1501000 2025-01-16  \n",
      "4      19.14       406750 2025-01-16  \n",
      "The date format has been updated and saved back to the same file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(r'F:\\DATA TEAM\\Process MCX\\Daywise File Process\\Current date file\\16.csv')\n",
    "\n",
    "# Check the data type of 'TradeDate'\n",
    "print(\"Data type of 'TradeDate':\", df['TradeDate'].dtype)\n",
    "\n",
    "# If 'TradeDate' is not a string, convert it to string first\n",
    "if not pd.api.types.is_string_dtype(df['TradeDate']):\n",
    "    df['TradeDate'] = df['TradeDate'].astype(str)\n",
    "\n",
    "# Now convert 'TradeDate' to datetime format\n",
    "try:\n",
    "    df['TradeDate'] = pd.to_datetime(df['TradeDate'].str.replace('/', '-'), format='%d-%m-%Y')\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Display the updated DataFrame (optional, you can remove this if not needed)\n",
    "print(\"Updated DataFrame:\\n\", df.head())\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV file\n",
    "df.to_csv(r'F:\\DATA TEAM\\Process MCX\\Daywise File Process\\Current date file\\16.csv', index=False)\n",
    "\n",
    "print(\"The date format has been updated and saved back to the same file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4bc373f-6f8d-468b-ab12-4a705d8221aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: F:\\DATA TEAM\\Process MCX\\Daywise File Process\\CLUB\\16.csv\n",
      "Merged: F:\\DATA TEAM\\Process MCX\\Daywise File Process\\CLUB\\ClUBMCX_15.csv\n",
      "All CSV files have been merged into 'F:\\DATA TEAM\\Process MCX\\Daywise File Process\\CLUB\\ClUBMCX_16.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# Path to the main folder\n",
    "main_folder_path = r'F:\\DATA TEAM\\Process MCX\\Daywise File Process\\CLUB'  # Use raw string literal to handle backslashes\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame() \n",
    "\n",
    "# Function to recursively search for CSV files and merge them\n",
    "def merge_csv_files(directory):\n",
    "    global merged_df\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV file (case insensitive)\n",
    "            if file.lower().endswith('.csv'):\n",
    "                # Construct the full path to the CSV file\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    if not df.empty:  # Check if DataFrame is not empty\n",
    "                        # Append the DataFrame to the merged DataFrame\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "                        print(f'Merged: {file_path}')  # Optional: print each file being merged\n",
    "                    else:\n",
    "                        print(f'Skipped empty file: {file_path}')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f'Skipped file with empty data: {file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing file {file_path}: {e}') \n",
    "\n",
    "# Call the function to start merging CSV files\n",
    "merge_csv_files(main_folder_path) \n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_file_path = os.path.join(main_folder_path, 'ClUBMCX_16.csv')\n",
    "merged_df.to_csv(output_file_path, index=False) \n",
    "\n",
    "print(f\"All CSV files have been merged into '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94500349-2b85-435c-a9b8-0ffb4317ddc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d61ac4-3545-427d-94fd-cff1815957d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc8ff4c3-21a2-4268-9267-c2dffa677ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert F:\\DATA TEAM\\MCX\\Cumulative\\2025\\JAN\\09012025 MCX.xls as Excel: Unsupported format, or corrupt file: Expected BOF record; found b'\\r\\n\\r\\n<TAB'\n",
      "Converted F:\\DATA TEAM\\MCX\\Cumulative\\2025\\JAN\\09012025 MCX.xls to F:\\DATA TEAM\\MCX\\Cumulative\\2025\\JAN\\09012025 MCX.csv as HTML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def convert_file_to_csv(file_path, csv_file_path):\n",
    "    try:\n",
    "        # Attempt to read the file as an Excel file\n",
    "        if file_path.endswith('.xls') or file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, engine='openpyxl' if file_path.endswith('.xlsx') else 'xlrd')\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, sep='\\t')  # In case it's tab-separated\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Converted {file_path} to {csv_file_path} as Excel\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {file_path} as Excel: {e}\")\n",
    "        \n",
    "        # Try reading as an HTML file if it contains web page data\n",
    "        try:\n",
    "            df = pd.read_html(file_path)[0]  # Read the first table\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Converted {file_path} to {csv_file_path} as HTML\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file_path} as HTML: {e}\")\n",
    "\n",
    "def convert_excel_to_csv(folder_path):\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check for Excel file extensions\n",
    "            if file.endswith('.xls') or file.endswith('.xlsx') or file.endswith('.html'):\n",
    "                # Define the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Define the CSV file path\n",
    "                csv_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.csv\")\n",
    "                \n",
    "                # Attempt conversion\n",
    "                convert_file_to_csv(file_path, csv_file_path)\n",
    "\n",
    "# Use a raw string for the folder path\n",
    "folder_path = r'F:\\DATA TEAM\\MCX\\Cumulative\\2025\\JAN'  # Change this to your folder path\n",
    "convert_excel_to_csv(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "753ab708-bccf-43f4-9873-dbb0b276b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_files(folder_path):\n",
    "    # Loop through all files in the folder\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Extract the date from the filename by removing non-date portions\n",
    "                # For example, from '09072024 MCX.csv', we only need '09072024'\n",
    "                date_value = ''.join(filter(str.isdigit, file))[:8]  # e.g., '09072024'\n",
    "                \n",
    "                # Convert to datetime using the correct format (DDMMYYYY)\n",
    "                date_obj = pd.to_datetime(date_value, format='%d%m%Y')\n",
    "                \n",
    "                # Manually format the date to remove leading zeros\n",
    "                formatted_date = f\"{date_obj.day}/{date_obj.month}/{date_obj.year}\"\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read the CSV file, skipping the first two rows\n",
    "                df = pd.read_csv(file_path, skiprows=2)\n",
    "                \n",
    "                # Add the TradeDate column with the formatted date\n",
    "                df['TradeDate'] = formatted_date\n",
    "                \n",
    "                # Convert 'TradeDate' column to datetime format (DD/MM/YYYY)\n",
    "                df['TradeDate'] = pd.to_datetime(df['TradeDate'], format='%d/%m/%Y')\n",
    "                \n",
    "                # Save the modified DataFrame back to the same file\n",
    "                df.to_csv(file_path, index=False)\n",
    "\n",
    "# Specify the path to your main folder\n",
    "main_folder = r'F:\\DATA TEAM\\MCX\\Cumulative\\2025\\JAN'  # or use forward slashes\n",
    "process_csv_files(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75dcc1-0b27-4967-a89e-76b81791cb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
