{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc9f4585-f711-4ef9-b361-b079f2b91c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded C:\\Users\\Administrator\\Desktop\\Apr_Match\\Clubed.csv with 2159469 rows.\n",
      "Loaded C:\\Users\\Administrator\\Desktop\\Apr_Match\\Data_227.csv with 76396 rows.\n",
      "\n",
      "Data from file C:\\Users\\Administrator\\Desktop\\Apr_Match\\Clubed.csv:\n",
      "\n",
      "Data from file C:\\Users\\Administrator\\Desktop\\Apr_Match\\Data_227.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\tmain_branch_code</th>\n",
       "      <th>BRANCH_CODE</th>\n",
       "      <th>CLIENT_ID</th>\n",
       "      <th>CompCon</th>\n",
       "      <th>SCRIP_SYMBOL</th>\n",
       "      <th>SCRIP_NAME</th>\n",
       "      <th>BUY_QUANTITY</th>\n",
       "      <th>BUY_GROSS_RATE</th>\n",
       "      <th>BUY_RATE</th>\n",
       "      <th>BUY_AMOUNT</th>\n",
       "      <th>SALE_QUANTITY</th>\n",
       "      <th>SALE_GROSS_RATE</th>\n",
       "      <th>SALE_RATE</th>\n",
       "      <th>SALE_AMOUNT</th>\n",
       "      <th>NET_QUANTITY</th>\n",
       "      <th>NET_RATE</th>\n",
       "      <th>NET_AMOUNT</th>\n",
       "      <th>TRADE_DATE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USERS</td>\n",
       "      <td>USERS</td>\n",
       "      <td>EXPOPT01</td>\n",
       "      <td>NSE_FNO  - Contract No:11</td>\n",
       "      <td>EF ADANIENT 25Apr2024</td>\n",
       "      <td>ADANIENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>3282.40</td>\n",
       "      <td>3282.4000</td>\n",
       "      <td>984720.0</td>\n",
       "      <td>-300</td>\n",
       "      <td>3282.40</td>\n",
       "      <td>984720.0</td>\n",
       "      <td>1/4/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USERS</td>\n",
       "      <td>USERS</td>\n",
       "      <td>EXPOPT01</td>\n",
       "      <td>NSE_FNO  - Contract No:11</td>\n",
       "      <td>EF ADANIPORTS 25Apr2024</td>\n",
       "      <td>ADANIPORTS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800</td>\n",
       "      <td>1386.60</td>\n",
       "      <td>1386.6000</td>\n",
       "      <td>1109280.0</td>\n",
       "      <td>-800</td>\n",
       "      <td>1386.60</td>\n",
       "      <td>1109280.0</td>\n",
       "      <td>1/4/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USERS</td>\n",
       "      <td>USERS</td>\n",
       "      <td>EXPOPT01</td>\n",
       "      <td>NSE_FNO  - Contract No:11</td>\n",
       "      <td>EF APOLLOHOSP 25Apr2024</td>\n",
       "      <td>APOLLOHOSP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "      <td>6483.90</td>\n",
       "      <td>6483.9000</td>\n",
       "      <td>810487.5</td>\n",
       "      <td>-125</td>\n",
       "      <td>6483.90</td>\n",
       "      <td>810487.5</td>\n",
       "      <td>1/4/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USERS</td>\n",
       "      <td>USERS</td>\n",
       "      <td>EXPOPT01</td>\n",
       "      <td>NSE_FNO  - Contract No:11</td>\n",
       "      <td>EF ASHOKLEY 25Apr2024</td>\n",
       "      <td>ASHOKLEY</td>\n",
       "      <td>15000</td>\n",
       "      <td>174.78</td>\n",
       "      <td>174.7833</td>\n",
       "      <td>2621750.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>174.38</td>\n",
       "      <td>174.3833</td>\n",
       "      <td>2615750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-6000.0</td>\n",
       "      <td>1/4/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USERS</td>\n",
       "      <td>USERS</td>\n",
       "      <td>EXPOPT01</td>\n",
       "      <td>NSE_FNO  - Contract No:11</td>\n",
       "      <td>EF ASIANPAINT 25Apr2024</td>\n",
       "      <td>ASIANPAINT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600</td>\n",
       "      <td>2881.68</td>\n",
       "      <td>2881.6833</td>\n",
       "      <td>1729010.0</td>\n",
       "      <td>-600</td>\n",
       "      <td>2881.68</td>\n",
       "      <td>1729010.0</td>\n",
       "      <td>1/4/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          \\tmain_branch_code  BRANCH_CODE  CLIENT_ID   \\\n",
       "0                       USERS        USERS   EXPOPT01   \n",
       "1                       USERS        USERS   EXPOPT01   \n",
       "2                       USERS        USERS   EXPOPT01   \n",
       "3                       USERS        USERS   EXPOPT01   \n",
       "4                       USERS        USERS   EXPOPT01   \n",
       "\n",
       "                     CompCon            SCRIP_SYMBOL  SCRIP_NAME   \\\n",
       "0  NSE_FNO  - Contract No:11    EF ADANIENT 25Apr2024    ADANIENT   \n",
       "1  NSE_FNO  - Contract No:11  EF ADANIPORTS 25Apr2024  ADANIPORTS   \n",
       "2  NSE_FNO  - Contract No:11  EF APOLLOHOSP 25Apr2024  APOLLOHOSP   \n",
       "3  NSE_FNO  - Contract No:11    EF ASHOKLEY 25Apr2024    ASHOKLEY   \n",
       "4  NSE_FNO  - Contract No:11  EF ASIANPAINT 25Apr2024  ASIANPAINT   \n",
       "\n",
       "   BUY_QUANTITY   BUY_GROSS_RATE   BUY_RATE   BUY_AMOUNT   SALE_QUANTITY   \\\n",
       "0              0             0.00     0.0000          0.0             300   \n",
       "1              0             0.00     0.0000          0.0             800   \n",
       "2              0             0.00     0.0000          0.0             125   \n",
       "3          15000           174.78   174.7833    2621750.0           15000   \n",
       "4              0             0.00     0.0000          0.0             600   \n",
       "\n",
       "   SALE_GROSS_RATE   SALE_RATE   SALE_AMOUNT   NET_QUANTITY   NET_RATE   \\\n",
       "0           3282.40   3282.4000      984720.0           -300    3282.40   \n",
       "1           1386.60   1386.6000     1109280.0           -800    1386.60   \n",
       "2           6483.90   6483.9000      810487.5           -125    6483.90   \n",
       "3            174.38    174.3833     2615750.0              0       0.00   \n",
       "4           2881.68   2881.6833     1729010.0           -600    2881.68   \n",
       "\n",
       "   NET_AMOUNT  TRADE_DATE1   \n",
       "0     984720.0     1/4/2024  \n",
       "1    1109280.0     1/4/2024  \n",
       "2     810487.5     1/4/2024  \n",
       "3      -6000.0     1/4/2024  \n",
       "4    1729010.0     1/4/2024  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Step 1: Specify the directory containing the CSV files\n",
    "file_path_pattern = r'C:\\Users\\Administrator\\Desktop\\Apr_Match\\*.csv'  # Update this path\n",
    "\n",
    "# Step 2: Get a list of all CSV files in the directory\n",
    "csv_files = glob.glob(file_path_pattern)\n",
    "\n",
    "# Step 3: Read each CSV file into a DataFrame and store them in a list\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "    print(f\"Loaded {file} with {len(df)} rows.\")\n",
    "\n",
    "# Step 4: Access data from each DataFrame\n",
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"\\nData from file {csv_files[i]}:\")\n",
    "    \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf369207-ba12-47b4-b3c6-f4745e579060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clubed Data Columns:\n",
      "Index(['Server', 'UserID', 'MAINTradeID', 'MAINOrderID', 'OrderID',\n",
      "       'ExchangeOrderNo', 'ExchangeTradeID', 'OrderTime', 'ExchangeOrderTime',\n",
      "       'ExchangeTradeTime', 'Exchange', 'SecurityID', 'Symbol', 'ExpiryDate',\n",
      "       'SecurityType', 'Side', 'OrderType', 'Quantity', 'PendingQuantity',\n",
      "       'Price', 'StrikePrice', 'ClientID', 'ReferenceText', 'CTCLID',\n",
      "       'MemberID', 'StrategyID', 'OptionType', 'OpenClose', 'ProductType',\n",
      "       'ManagerID', 'Pancard', 'TerminalInfo', 'AlgoID', 'AlgoCategory',\n",
      "       'ParticipantID', 'Multiplier'],\n",
      "      dtype='object')\n",
      "\n",
      "Data 227 Columns:\n",
      "Index(['main_branch_code', 'BRANCH_CODE', 'CLIENT_ID', 'CompCon',\n",
      "       'SCRIP_SYMBOL', 'SCRIP_NAME', 'BUY_QUANTITY', 'BUY_GROSS_RATE',\n",
      "       'BUY_RATE', 'BUY_AMOUNT', 'SALE_QUANTITY', 'SALE_GROSS_RATE',\n",
      "       'SALE_RATE', 'SALE_AMOUNT', 'NET_QUANTITY', 'NET_RATE', 'NET_AMOUNT',\n",
      "       'TRADE_DATE1'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "len(right_on) must equal len(left_on)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_227\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Step 3: Merge the two DataFrames on the specified columns\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m     24\u001b[0m     clubbed_data,\n\u001b[0;32m     25\u001b[0m     data_227,\n\u001b[0;32m     26\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m     left_on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mManagerID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpiryDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOption Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrike Price\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrade_Date\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Adjust as necessary\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     right_on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLIENT_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCRIP_SYMBOL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCRIP_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRADE_DATE1\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Corrected keys\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Step 4: Save the merged DataFrame to a new CSV file\u001b[39;00m\n\u001b[0;32m     32\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAdministrator\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmatched_output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[0;32m    173\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    174\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    175\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    176\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    177\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    178\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    179\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    180\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    181\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:786\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    779\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    780\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot allowed to merge between different levels. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_left\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m levels on the left, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_right\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on the right)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    783\u001b[0m     )\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[1;32m--> 786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_on, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_left_right_on(left_on, right_on)\n\u001b[0;32m    788\u001b[0m (\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    793\u001b[0m     right_drop,\n\u001b[0;32m    794\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1628\u001b[0m, in \u001b[0;36m_MergeOperation._validate_left_right_on\u001b[1;34m(self, left_on, right_on)\u001b[0m\n\u001b[0;32m   1626\u001b[0m         left_on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m n\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(right_on) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(left_on):\n\u001b[1;32m-> 1628\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen(right_on) must equal len(left_on)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left_on, right_on\n",
      "\u001b[1;31mValueError\u001b[0m: len(right_on) must equal len(left_on)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the clubbed file\n",
    "clubbed_file_path = r'C:\\Users\\Administrator\\Desktop\\Apr_Match\\clubed.csv'\n",
    "clubbed_data = pd.read_csv(clubbed_file_path)\n",
    "\n",
    "# Step 2: Load the data 227 file\n",
    "data_227_file_path = r'C:\\Users\\Administrator\\Desktop\\Apr_Match\\data_227.csv'\n",
    "data_227 = pd.read_csv(data_227_file_path)\n",
    "\n",
    "# Remove leading/trailing spaces from column names\n",
    "clubbed_data.columns = clubbed_data.columns.str.strip()\n",
    "data_227.columns = data_227.columns.str.strip()\n",
    "\n",
    "# Print column names for debugging\n",
    "print(\"Clubed Data Columns:\")\n",
    "print(clubbed_data.columns)\n",
    "\n",
    "print(\"\\nData 227 Columns:\")\n",
    "print(data_227.columns)\n",
    "\n",
    "# Step 3: Merge the two DataFrames on the specified columns\n",
    "merged_data = pd.merge(\n",
    "    clubbed_data,\n",
    "    data_227,\n",
    "    how='inner',\n",
    "    left_on=['ManagerID', 'Symbol', 'ExpiryDate', 'Option Type', 'Strike Price', 'Trade_Date'],  # Adjust as necessary\n",
    "    right_on=['CLIENT_ID', 'SCRIP_SYMBOL', 'SCRIP_NAME', 'TRADE_DATE1']  # Corrected keys\n",
    ")\n",
    "\n",
    "# Step 4: Save the merged DataFrame to a new CSV file\n",
    "output_file_path = r'C:\\Users\\Administrator\\Desktop\\matched_output.csv'\n",
    "merged_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Matching rows saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3668633-f83f-4e26-9bf0-f957f103181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: C:\\Users\\Administrator\\Desktop\\Clubed.csv\n",
      "File not found: C:\\Users\\Administrator\\Desktop\\Data_227.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file paths\n",
    "clubed_path = r'C:\\Users\\Administrator\\Desktop\\Clubed.csv'\n",
    "data227_path = r'C:\\Users\\Administrator\\Desktop\\Data_227.csv'\n",
    "\n",
    "# Check if the files exist\n",
    "if not os.path.isfile(clubed_path):\n",
    "    print(f\"File not found: {clubed_path}\")\n",
    "if not os.path.isfile(data227_path):\n",
    "    print(f\"File not found: {data227_path}\")\n",
    "\n",
    "# Load the CSV files into DataFrames if they exist\n",
    "if os.path.isfile(clubed_path) and os.path.isfile(data227_path):\n",
    "    df_clubed = pd.read_csv(clubed_path)\n",
    "    df_data227 = pd.read_csv(data227_path)\n",
    "\n",
    "    # Clean column names by stripping whitespace\n",
    "    df_clubed.columns = df_clubed.columns.str.strip()\n",
    "    df_data227.columns = df_data227.columns.str.strip()\n",
    "\n",
    "    # Function to create token format for Clubed Data\n",
    "    def create_token_clubed(row):\n",
    "        return f\"{row['ManagerID']} {row['OptionType']} {row['Symbol']} {row['ExpiryDate']} {row['StrikePrice']}\"\n",
    "\n",
    "    # Function to create token format for Data227\n",
    "    def create_token_data227(row):\n",
    "        return f\"{row['CLIENT_ID']} {row['SCRIP_SYMBOL']}\"\n",
    "\n",
    "    # Create the token columns in both DataFrames\n",
    "    df_clubed['Token'] = df_clubed.apply(create_token_clubed, axis=1)\n",
    "    df_data227['Token'] = df_data227.apply(create_token_data227, axis=1)\n",
    "\n",
    "    # Debugging: Print the first few tokens\n",
    "    print(\"Sample Tokens from Clubed DataFrame:\")\n",
    "    print(df_clubed['Token'].head())\n",
    "\n",
    "    print(\"Sample Tokens from Data227 DataFrame:\")\n",
    "    print(df_data227['Token'].head())\n",
    "\n",
    "    # Merge DataFrames on the token column\n",
    "    merged_df = pd.merge(df_clubed, df_data227, on='Token', suffixes=('_clubed', '_data227'))\n",
    "\n",
    "    # Check for any matches\n",
    "    if merged_df.empty:\n",
    "        print(\"No matches found.\")\n",
    "    else:\n",
    "        # Select relevant columns: token, buyquantity, and sellquantity\n",
    "        result_df = merged_df[['Token', 'BUY_QUANTITY', 'SALE_QUANTITY']]\n",
    "\n",
    "        # Display the result\n",
    "        print(result_df)\n",
    "\n",
    "    # Optionally, save the result to a CSV file\n",
    "    result_df.to_csv('matched_quantities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf7a12f-b4bf-49f6-bf86-032704608dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the directory:\n",
      ".ipynb_checkpoints\n",
      "02042024\n",
      "1-Temp_Recent_Run_Clean.bat\n",
      "2-Chrome_History_Delete.bat\n",
      "3-RDP_History_Clear.bat\n",
      "890 Data\n",
      "All codes for Data\n",
      "AryaFin_Solo\n",
      "Backup_Data.csv\n",
      "Backup_Data_227.csv\n",
      "BSE & NSE BhavCopy\n",
      "closeAmt.txt\n",
      "Clubed.csv\n",
      "Data_227.csv\n",
      "desktop.ini\n",
      "exp-4-01-and 02-4.CSV\n",
      "matching.txt\n",
      "Merged Files\n",
      "MoneyMaker Solo.appref-ms\n",
      "Trade 1-Apr-2024 - 1.xlsx\n",
      "Trade 1-Apr-2024 - 3.xlsx\n",
      "Tradebook\n",
      "Trading_Data_DA\n",
      "User List.xlsx\n",
      "~$Nifty.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory\n",
    "directory = r'C:\\Users\\Administrator\\Desktop'\n",
    "\n",
    "# List files in the directory\n",
    "files = os.listdir(directory)\n",
    "print(\"Files in the directory:\")\n",
    "for file in files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfa81b02-9f4c-4fc3-9c0e-550302cfa081",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OptionType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OptionType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m df_data227[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCRIP_SYMBOL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_data227[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCRIP_SYMBOL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Add 'XX' to OptionType where it is blank for all symbols\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m df_data227\u001b[38;5;241m.\u001b[39mloc[df_data227[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptionType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull() \u001b[38;5;241m|\u001b[39m (df_data227[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptionType\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptionType\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXX\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Function to create token format for Clubed Data\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_token_clubed\u001b[39m(row):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OptionType'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file paths\n",
    "clubed_path = r'C:\\Users\\Administrator\\Desktop\\Clubed.csv'\n",
    "data227_path = r'C:\\Users\\Administrator\\Desktop\\Data_227.csv'\n",
    "\n",
    "# Check if the files exist\n",
    "if not os.path.isfile(clubed_path):\n",
    "    print(f\"File not found: {clubed_path}\")\n",
    "if not os.path.isfile(data227_path):\n",
    "    print(f\"File not found: {data227_path}\")\n",
    "\n",
    "# Load the CSV files into DataFrames if they exist\n",
    "if os.path.isfile(clubed_path) and os.path.isfile(data227_path):\n",
    "    df_clubed = pd.read_csv(clubed_path)\n",
    "    df_data227 = pd.read_csv(data227_path)\n",
    "\n",
    "    # Clean column names by stripping whitespace\n",
    "    df_clubed.columns = df_clubed.columns.str.strip()\n",
    "    df_data227.columns = df_data227.columns.str.strip()\n",
    "\n",
    "    # Update SCRIP_SYMBOL: remove 'EF' and 'IO'\n",
    "    df_data227['SCRIP_SYMBOL'] = df_data227['SCRIP_SYMBOL'].str.replace('EF', '').str.replace('IO', '')\n",
    "\n",
    "    # Add 'XX' to OptionType where it is blank for all symbols\n",
    "    df_data227.loc[df_data227['OptionType'].isnull() | (df_data227['OptionType'] == ''), 'OptionType'] = 'XX'\n",
    "\n",
    "    # Function to create token format for Clubed Data\n",
    "    def create_token_clubed(row):\n",
    "        return f\"{row['ManagerID']} {row['OptionType']} {row['Symbol']} {row['ExpiryDate']} {row['StrikePrice']}\"\n",
    "\n",
    "    # Function to create token format for Data227\n",
    "    def create_token_data227(row):\n",
    "        return f\"{row['CLIENT_ID']} {row['SCRIP_SYMBOL']}\"\n",
    "\n",
    "    # Create the token columns in both DataFrames\n",
    "    df_clubed['Token'] = df_clubed.apply(create_token_clubed, axis=1)\n",
    "    df_data227['Token'] = df_data227.apply(create_token_data227, axis=1)\n",
    "\n",
    "    # Debugging: Print the first few tokens\n",
    "    print(\"Sample Tokens from Clubed DataFrame:\")\n",
    "    print(df_clubed['Token'].head())\n",
    "\n",
    "    print(\"Sample Tokens from Data227 DataFrame:\")\n",
    "    print(df_data227['Token'].head())\n",
    "\n",
    "    # Merge DataFrames on the token column\n",
    "    merged_df = pd.merge(df_clubed, df_data227, on='Token', suffixes=('_clubed', '_data227'))\n",
    "\n",
    "    # Check for any matches\n",
    "    if merged_df.empty:\n",
    "        print(\"No matches found.\")\n",
    "    else:\n",
    "        # Select relevant columns: token, buyquantity, and sellquantity\n",
    "        result_df = merged_df[['Token', 'BUY_QUANTITY', 'SALE_QUANTITY']]\n",
    "\n",
    "        # Display the result\n",
    "        print(result_df)\n",
    "\n",
    "    # Optionally, save the result to a CSV file\n",
    "    result_df.to_csv('matched_quantities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f3e5f-bfe5-4727-8fbc-857ac2600305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
