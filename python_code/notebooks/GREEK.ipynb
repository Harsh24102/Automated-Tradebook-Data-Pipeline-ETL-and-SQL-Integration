{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9554d6eb-a7a7-4cb4-a0e4-4cc885804f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\Curent Date File\\19062025.xls as Excel: Pandas requires version '2.0.1' or newer of 'xlrd' (version '1.2.0' currently installed).\n",
      "Converted E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\Curent Date File\\19062025.xls to E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\Curent Date File\\19062025.csv as HTML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def convert_file_to_csv(file_path, csv_file_path):\n",
    "    try:\n",
    "        # Attempt to read the file as an Excel file\n",
    "        if file_path.endswith('.xls') or file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, engine='openpyxl' if file_path.endswith('.xlsx') else 'xlrd')\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, sep='\\t')  # In case it's tab-separated\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Converted {file_path} to {csv_file_path} as Excel\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {file_path} as Excel: {e}\")\n",
    "        \n",
    "        # Try reading as an HTML file if it contains web page data\n",
    "        try:\n",
    "            df = pd.read_html(file_path)[0]  # Read the first table\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Converted {file_path} to {csv_file_path} as HTML\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file_path} as HTML: {e}\")\n",
    "\n",
    "def convert_excel_to_csv(folder_path):\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check for Excel file extensions\n",
    "            if file.endswith('.xls') or file.endswith('.xlsx') or file.endswith('.html'):\n",
    "                # Define the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Define the CSV file path\n",
    "                csv_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.csv\")\n",
    "                \n",
    "                # Attempt conversion\n",
    "                convert_file_to_csv(file_path, csv_file_path)\n",
    "\n",
    "# Use a raw string for the folder path\n",
    "folder_path = r'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\Curent Date File'  # Change this to your folder path\n",
    "convert_excel_to_csv(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bf6c0a-b906-4b9f-886d-5a22f8f476de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_files(folder_path):\n",
    "    all_data = []  # List to hold all dataframes\n",
    "\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Extract the date from the filename (remove the .csv extension)\n",
    "                date_value = file[:-4]  # e.g., '01042024'\n",
    "                \n",
    "                # Convert to datetime using the correct format (DDMMYYYY)\n",
    "                formatted_date = pd.to_datetime(date_value, format='%d%m%Y').strftime('%d-%m-%Y')\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read the CSV file, skipping the first two rows\n",
    "                df = pd.read_csv(file_path, skiprows=2)\n",
    "                \n",
    "                # Add the TradeDate column with the formatted date\n",
    "                df['TradeDate'] = formatted_date\n",
    "                \n",
    "                # Append the modified DataFrame to the list\n",
    "                all_data.append(df)\n",
    "\n",
    "    # Combine all dataframes into one\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a new CSV file \n",
    "    combined_df.to_csv(os.path.join(folder_path, '19.csv'), index=False)\n",
    "\n",
    "# Specify the path to your main folder\n",
    "main_folder = r'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\Curent Date File'  # or use forward slashes\n",
    "process_csv_files(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6fe10d-e085-4a53-b875-7bf8b2aab0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'TradeDate': object\n",
      "Updated DataFrame:\n",
      "   CLIENT_ID COMPANY_CODE                SCRIP_SYMBOL  NET_QUANTITY  NET_RATE  \\\n",
      "0  FUTOPT01  DERIVATIVES  AUBANK 26Jun25 CE 700.0000             0      0.00   \n",
      "1  FUTOPT01  DERIVATIVES  AUBANK 26Jun25 CE 770.0000         -1000     29.00   \n",
      "2  FUTOPT01  DERIVATIVES  AUBANK 26Jun25 CE 800.0000         -1000     14.45   \n",
      "3  FUTOPT01  DERIVATIVES  AUBANK 26Jun25 PE 700.0000             0      0.00   \n",
      "4  FUTOPT01  DERIVATIVES  AUBANK 26Jun25 PE 770.0000         -1000      5.65   \n",
      "\n",
      "   NET_AMOUNT  CLOSING_PRICE  NOT_PROFIT  TRADING_QUANTITY  TRADING_AMOUNT  \\\n",
      "0    -10050.0            0.0    -10050.0             -1000           94.65   \n",
      "1     29000.0           27.0      2000.0             -1000           29.00   \n",
      "2     14450.0            8.7      5750.0                 0            0.00   \n",
      "3       100.0            0.0       100.0             -1000            0.50   \n",
      "4      5650.0            4.8       850.0             -1000            5.65   \n",
      "\n",
      "   BUY_QUANTITY  BUY_RATE  BUY_AMOUNT  SALE_QUANTITY  SALE_RATE  SALE_AMOUNT  \\\n",
      "0          1000     104.7      104700              0       0.00            0   \n",
      "1             0       0.0           0              0       0.00            0   \n",
      "2             0       0.0           0           1000      14.45        14450   \n",
      "3          1000       0.4         400              0       0.00            0   \n",
      "4             0       0.0           0              0       0.00            0   \n",
      "\n",
      "   TradeDate  \n",
      "0 2025-06-19  \n",
      "1 2025-06-19  \n",
      "2 2025-06-19  \n",
      "3 2025-06-19  \n",
      "4 2025-06-19  \n",
      "The date format has been updated and saved back to the same file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(r'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\Curent Date File\\19.csv')\n",
    "\n",
    "# Check the data type of 'TradeDate'\n",
    "print(\"Data type of 'TradeDate':\", df['TradeDate'].dtype)\n",
    "\n",
    "# If 'TradeDate' is not a string, convert it to string first\n",
    "if not pd.api.types.is_string_dtype(df['TradeDate']):\n",
    "    df['TradeDate'] = df['TradeDate'].astype(str)\n",
    "\n",
    "# Now convert 'TradeDate' to datetime format\n",
    "try:\n",
    "    df['TradeDate'] = pd.to_datetime(df['TradeDate'].str.replace('/', '-'), format='%d-%m-%Y')\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Display the updated DataFrame (optional, you can remove this if not needed)\n",
    "print(\"Updated DataFrame:\\n\", df.head())\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV file\n",
    "df.to_csv(r'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\Curent Date File\\19.csv', index=False)\n",
    "\n",
    "print(\"The date format has been updated and saved back to the same file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c893a5-a76b-42cd-b133-8340ff6dc6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\CLUB\\19.csv\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\CLUB\\25_ClubG18.csv\n",
      "All CSV files have been merged into 'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\CLUB\\25_ClubG_19.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# Path to the main folder\n",
    "main_folder_path = r'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\CLUB'  # Use raw string literal to handle backslashes\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame() \n",
    "\n",
    "# Function to recursively search for CSV files and merge them\n",
    "def merge_csv_files(directory):\n",
    "    global merged_df\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV file (case insensitive)\n",
    "            if file.lower().endswith('.csv'):\n",
    "                # Construct the full path to the CSV file\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    if not df.empty:  # Check if DataFrame is not empty\n",
    "                        # Append the DataFrame to the merged DataFrame\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "                        print(f'Merged: {file_path}')  # Optional: print each file being merged\n",
    "                    else:\n",
    "                        print(f'Skipped empty file: {file_path}')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f'Skipped file with empty data: {file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing file {file_path}: {e}') \n",
    "\n",
    "# Call the function to start merging CSV files\n",
    "merge_csv_files(main_folder_path) \n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_file_path = os.path.join(main_folder_path, '25_ClubG_19.csv')\n",
    "merged_df.to_csv(output_file_path, index=False) \n",
    "\n",
    "print(f\"All CSV files have been merged into '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3fba4-3587-401e-8a71-9abd9536ab14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86011c-7a35-40f9-9536-c03fedd33857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aeddd7-5ae4-4550-8bd8-9d085f599616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02122b4-7109-4b63-a7a1-6b9395f68bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42d08f-bafb-475f-b02d-ded66803269d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319abeb-f7ca-4e87-82ea-76fe8ec9ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66e2d3-4022-4dfd-9b28-2f0c6393f94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146efac3-c400-49ef-a707-00de1a527e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b803a-234c-422d-a158-3c5e5ec22062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650e0c9-59df-48f8-8086-f3285fcea5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d3611-d2b5-48c3-ba22-f19ae5f4e25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1771e3-e68a-4ec7-8ff5-4dd551945b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2058cc3-46a0-4c25-bf72-bfde0ca75e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92ed9d-02ed-4fd7-a8be-f5dc586c6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36487323-71d0-44d4-b33b-2468385279a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3de36-11be-45f7-8cd6-59b840a17a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c606e-d767-4de6-9a69-482aed9a53cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6ef0c-64fd-4fb1-84ca-758f58716dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c46f0-e13c-4071-831b-ee6ba6c02c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4fc86-83b0-490b-a612-82487f4c5106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf36b3b-7abc-4ca2-b156-f2d6c17de54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d0e424-7993-4293-9dff-375a23fd3e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c0adb-d327-42e2-abaa-ff9f0114a535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bd432-92a6-4d54-b597-bfdbfbdb2211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04a29f-be0d-4559-846e-627d353f014d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4858af6e-f6e0-49d1-93c3-b9e37361cde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\2425\\25_ClubG_22.csv\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\2425\\ClubG28.csv\n",
      "All CSV files have been merged into 'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\2425\\25_ClubG_start to till date.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# Path to the main folder\n",
    "main_folder_path = r'E:\\Back-Up Files\\Data Team\\2024-2025\\GREEK\\2425'  # Use raw string literal to handle backslashes\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame() \n",
    "\n",
    "# Function to recursively search for CSV files and merge them\n",
    "def merge_csv_files(directory):\n",
    "    global merged_df\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV file (case insensitive)\n",
    "            if file.lower().endswith('.csv'):\n",
    "                # Construct the full path to the CSV file\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    if not df.empty:  # Check if DataFrame is not empty\n",
    "                        # Append the DataFrame to the merged DataFrame\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "                        print(f'Merged: {file_path}')  # Optional: print each file being merged\n",
    "                    else:\n",
    "                        print(f'Skipped empty file: {file_path}')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f'Skipped file with empty data: {file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing file {file_path}: {e}') \n",
    "\n",
    "# Call the function to start merging CSV files\n",
    "merge_csv_files(main_folder_path) \n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_file_path = os.path.join(main_folder_path, '25_ClubG_start to till date.csv')\n",
    "merged_df.to_csv(output_file_path, index=False) \n",
    "\n",
    "print(f\"All CSV files have been merged into '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6225e6-581e-4cab-9663-3e185b1b6778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
