{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2547b8cd-22a2-4b76-871b-5ae150ffdec0",
   "metadata": {},
   "source": [
    "## For CSV. File Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88715820-f25f-494a-b022-7bc6193ee28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250401.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250402.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250403.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250404.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250407.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250408.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250409.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250411.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250415.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250416.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250417.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250421.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250422.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250423.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250424.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250425.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250428.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250429.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250430.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250502.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250505.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250506.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250507.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250508.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250509.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250512.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250513.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250514.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250515.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250516.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250519.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250520.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250521.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250522.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250523.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250526.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250527.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250528.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250529.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250530.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250602.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250603.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250604.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250605.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250606.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250609.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250610.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250611.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250612.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250613.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250616.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250617.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250618.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250619.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250620.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250623.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250624.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250625.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250626.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250627.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250630.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250701.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250702.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250703.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250704.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250707.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250708.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250709.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250710.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250711.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250714.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250715.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250716.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250717.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250718.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250721.csv\n",
      "\n",
      "✅ Clean merge complete: 'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\Merged(ALL+EXP+NFT+MCX)\\Merged_NFT.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths\n",
    "main_folder_path = r'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT'\n",
    "output_folder_path = r'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\Merged(ALL+EXP+NFT+MCX)'\n",
    "output_file_path = os.path.join(output_folder_path, 'Merged_NFT.csv')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Track header to detect repeated headers\n",
    "seen_header = None\n",
    "header_written = False\n",
    "\n",
    "# Open output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "    for root, dirs, files in os.walk(main_folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "                        lines = infile.readlines()\n",
    "                        if not lines:\n",
    "                            print(f\"Skipped empty file: {file_path}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Identify header from current file\n",
    "                        current_header = lines[0].strip()\n",
    "\n",
    "                        # Write header only once\n",
    "                        if not header_written:\n",
    "                            outfile.write(current_header + '\\n')\n",
    "                            seen_header = current_header\n",
    "                            header_written = True\n",
    "\n",
    "                        # Write lines skipping header or repeated headers in between\n",
    "                        for line in lines[1:]:\n",
    "                            # Skip lines that match the header exactly\n",
    "                            if line.strip() == seen_header:\n",
    "                                continue\n",
    "                            outfile.write(line)\n",
    "                    \n",
    "                    print(f\"Merged: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Clean merge complete: '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f99a89-42ff-47be-8a0a-bffc363745e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting merge...\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250401.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250402.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250403.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250404.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250407.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250408.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250409.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250411.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250415.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250416.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250417.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250421.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250422.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250423.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250424.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250425.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250428.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250429.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250430.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250502.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250505.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250506.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250507.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250508.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250509.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250512.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250513.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250514.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250515.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250516.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250519.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250520.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250521.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250522.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250523.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250526.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250527.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250528.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250529.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250530.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250602.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250603.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250604.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250605.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250606.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250609.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250610.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250611.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250612.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250613.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250616.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250617.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250618.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250619.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250620.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250623.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250624.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250625.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250626.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250627.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250630.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250701.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250702.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250703.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250704.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250707.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250708.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250709.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250710.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250711.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250714.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250715.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250716.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250717.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250718.csv\n",
      "Merged: E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT\\MergedNFT_20250721.csv\n",
      "\n",
      "✅ Clean merge complete: 'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\Merged(ALL+EXP+NFT+MCX)\\Merged_NFT.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "main_folder_path = r'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_NFT'\n",
    "output_folder_path = r'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\Merged(ALL+EXP+NFT+MCX)'\n",
    "output_file_path = os.path.join(output_folder_path, 'Merged_NFT.csv')\n",
    "\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Your exact header line as a string\n",
    "header_line = \"1\\t9999\\t\\tReferenceNo\\tSymbol1\\tExpiry1\\tprice1\\tQty1\\tSymbol2\\tExpiry2\\tStrikePrice2\\tOption2\\tprice2\\tQty2\\tSymbol3\\tExpiry3\\tStrikePrice3\\tOption3\\tprice3\\tQty3\\tprice4\\tQty4\\tSpreadSide\\tParity\\tParityLive\\tDisparity\\tSpinName\\tEntryTime\\tErrorText\\tRefFuture\\tRefSpot\"\n",
    "\n",
    "# Split header by tab to get list of columns\n",
    "main_header = header_line.split('\\t')\n",
    "\n",
    "noise_phrases = [\n",
    "    \"order value exceeds\", \"due to l2 cancel\", \"due to l3 cancel\",\n",
    "    \"groupname\", \"manager:\", \"exceeded\", \"assigned:\", \"required:\"\n",
    "]\n",
    "\n",
    "def is_noise_line(line):\n",
    "    low_line = line.lower()\n",
    "    return any(phrase in low_line for phrase in noise_phrases)\n",
    "\n",
    "def parse_and_align(line):\n",
    "    parts = line.strip().split('\\t')\n",
    "    if len(parts) < len(main_header):\n",
    "        return None\n",
    "    # Keep only as many columns as header has\n",
    "    return parts[:len(main_header)]\n",
    "\n",
    "print(\"Starting merge...\")\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter='\\t')\n",
    "    writer.writerow(main_header)  # write your exact header properly split\n",
    "\n",
    "    for root, dirs, files in os.walk(main_folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "                        for line in infile:\n",
    "                            if ('ReferenceNo' in line) or is_noise_line(line) or not line.strip():\n",
    "                                continue\n",
    "                            aligned_row = parse_and_align(line)\n",
    "                            if aligned_row:\n",
    "                                writer.writerow(aligned_row)\n",
    "                    print(f\"Merged: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Clean merge complete: '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48572575-01eb-4b82-8415-c4875ef27e33",
   "metadata": {},
   "source": [
    "## For Xlsx. File Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f9cf6-92d3-49e2-aed5-3b2912057cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "# Input/output paths\n",
    "main_folder_path = r'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\MERGE_ALL'\n",
    "output_folder_path = r'E:\\DATA\\2025-2026\\MERGE_SPREADBOOK\\Merged'\n",
    "output_file_path = os.path.join(output_folder_path, 'Merged_ALL.xlsx')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Create new workbook for output\n",
    "merged_wb = Workbook()\n",
    "merged_ws = merged_wb.active\n",
    "merged_ws.title = \"MergedData\"\n",
    "\n",
    "# Track if header has been written\n",
    "header_written = False\n",
    "\n",
    "# Merge function\n",
    "for root, dirs, files in os.walk(main_folder_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.xlsx'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                wb = load_workbook(file_path, read_only=True, data_only=True)\n",
    "                sheet = wb.active  # assuming data is in the first sheet\n",
    "\n",
    "                rows = sheet.iter_rows(values_only=True)\n",
    "                header = next(rows, None)\n",
    "\n",
    "                if not header:\n",
    "                    print(f\"Skipped empty Excel file: {file_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Write header only once\n",
    "                if not header_written:\n",
    "                    merged_ws.append(header)\n",
    "                    header_written = True\n",
    "\n",
    "                # Write the rest of the data\n",
    "                for row in rows:\n",
    "                    merged_ws.append(row)\n",
    "\n",
    "                print(f\"Merged: {file_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Save the final merged workbook\n",
    "merged_wb.save(output_file_path)\n",
    "print(f\"\\n✅ Fast Excel merge complete: '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec9810-239c-4c72-ba76-877c38bbaaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
