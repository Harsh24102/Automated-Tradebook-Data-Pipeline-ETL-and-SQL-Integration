{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1035881-4647-451e-8c47-30b06f775680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File\\DAYWISE_890_20062025_12020245071002100953_YASH.xls: Pandas requires version '2.0.1' or newer of 'xlrd' (version '1.2.0' currently installed).\n",
      "Converted E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File\\DAYWISE_890_20062025_12020245071002100953_YASH.xls to E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File\\DAYWISE_890_20062025_12020245071002100953_YASH.csv as HTML\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File\\DAYWISE_890_20062025_12020245071002100953_YASH.csv\n",
      "All CSV files have been merged into 'E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File\\19062025.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert files (.xls, .xlsx, .html) to CSV\n",
    "def convert_file_to_csv(file_path, csv_file_path):\n",
    "    try:\n",
    "        # Attempt to read the file as an Excel file, skipping the first two rows\n",
    "        if file_path.endswith('.xls') or file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, engine='openpyxl' if file_path.endswith('.xlsx') else 'xlrd', skiprows=2)\n",
    "        else:\n",
    "            # If it's a CSV, skip the first two rows\n",
    "            df = pd.read_csv(file_path, skiprows=2)  # Skip the first 2 rows for CSV files\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Converted {file_path} to {csv_file_path} as Excel or CSV\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {file_path}: {e}\")\n",
    "        \n",
    "        # Try reading as an HTML file if it contains web page data\n",
    "        try:\n",
    "            df = pd.read_html(file_path)[0]  # Read the first table\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Converted {file_path} to {csv_file_path} as HTML\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file_path} as HTML: {e}\")\n",
    "\n",
    "# Function to recursively search for files (.xls, .xlsx, .html) and convert them to CSV\n",
    "def convert_files_to_csv(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check for .xls, .xlsx, .html extensions\n",
    "            if file.endswith('.xls') or file.endswith('.xlsx') or file.endswith('.html') or file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                csv_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.csv\")\n",
    "                \n",
    "                # Convert the file to CSV\n",
    "                convert_file_to_csv(file_path, csv_file_path)\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Function to recursively search for CSV files and merge them\n",
    "def merge_csv_files(directory):\n",
    "    global merged_df\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV file (case insensitive)\n",
    "            if file.lower().endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read the CSV file into a DataFrame, skipping the first two rows\n",
    "                    df = pd.read_csv(file_path, skiprows=2)  # Skipping the first 2 rows when reading CSV files\n",
    "                    if not df.empty:\n",
    "                        # Append the DataFrame to the merged DataFrame\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "                        print(f'Merged: {file_path}')\n",
    "                    else:\n",
    "                        print(f'Skipped empty file: {file_path}')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f'Skipped file with empty data: {file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing file {file_path}: {e}')\n",
    "\n",
    "# Function to perform the entire process of conversion and merging\n",
    "def convert_and_merge_files(folder_path):\n",
    "    # Convert all relevant files (.xls, .xlsx, .html) to CSV\n",
    "    convert_files_to_csv(folder_path)\n",
    "    \n",
    "    # Merge all CSV files found in the folder\n",
    "    merge_csv_files(folder_path)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    output_file_path = os.path.join(folder_path, '19062025.csv')\n",
    "    merged_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"All CSV files have been merged into '{output_file_path}'\")\n",
    "\n",
    "# Define the folder path (use raw string to avoid issues with backslashes)\n",
    "folder_path = r'E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File'  # Update with your folder path\n",
    "\n",
    "# Perform the conversion and merging process\n",
    "convert_and_merge_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ae0ac9-d1e6-49d8-b325-d5a3eb21b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_files(folder_path):\n",
    "    all_data = []  # List to hold all dataframes\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Extract the date from the filename (remove the .csv extension)\n",
    "                date_value = file[:-4]  # e.g., '01042024'\n",
    "                \n",
    "                # Convert to datetime using the correct format (DDMMYYYY)\n",
    "                formatted_date = pd.to_datetime(date_value, format='%d%m%Y').strftime('%d-%m-%Y')\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read the CSV file (without skipping any rows)\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Add the TradeDate column with the formatted date\n",
    "                df['TradeDate'] = formatted_date\n",
    "                \n",
    "                # Append the modified DataFrame to the list\n",
    "                all_data.append(df)\n",
    "\n",
    "    # Combine all dataframes into one\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a new CSV file \n",
    "    combined_df.to_csv(os.path.join(folder_path, '19.csv'), index=False)\n",
    "\n",
    "# Specify the path to your main folder\n",
    "main_folder = r'E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File'  # or use forward slashes\n",
    "process_csv_files(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf9a404-dbf1-4cac-a67b-3bb258439d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'TradeDate': object\n",
      "Updated DataFrame:\n",
      "   CLIENT_ID COMPANY_CODE                 SCRIP_SYMBOL  NET_QUANTITY  NET_RATE  \\\n",
      "0  ADPALL01  DERIVATIVES  NIFTY 19Jun25 CE 24800.0000             0    0.0000   \n",
      "1  ADPALL01  DERIVATIVES  NIFTY 19Jun25 CE 24900.0000             0    0.0000   \n",
      "2  ADPALL01  DERIVATIVES  NIFTY 19Jun25 PE 24800.0000             0    0.0000   \n",
      "3  ADPALL01  DERIVATIVES  NIFTY 19Jun25 PE 24900.0000             0    0.0000   \n",
      "4  ADPALL01  DERIVATIVES  NIFTY 26Jun25 CE 24900.0000          2625  151.4114   \n",
      "\n",
      "   NET_AMOUNT  CLOSING_PRICE  NOT_PROFIT  TRADING_QUANTITY  TRADING_AMOUNT  \\\n",
      "0    49541.25           0.00    49541.25                 0            0.00   \n",
      "1   -55875.00           0.00   -55875.00              1950           42.45   \n",
      "2    -8313.75           0.00    -8313.75                 0            0.00   \n",
      "3    83718.75           0.00    83718.75             -1950          142.70   \n",
      "4  -397455.00         142.05   -24573.75                 0            0.00   \n",
      "\n",
      "   BUY_QUANTITY  BUY_RATE  BUY_AMOUNT  SALE_QUANTITY  SALE_RATE  SALE_AMOUNT  \\\n",
      "0          1725     26.16       45120           1725      54.88        94661   \n",
      "1             0      0.00           0           1950      13.80        26903   \n",
      "2          1725     23.15       39938           1725      18.33        31624   \n",
      "3          1950     99.77      194546              0       0.00            0   \n",
      "4          2625    151.41      397455              0       0.00            0   \n",
      "\n",
      "   TradeDate  \n",
      "0 2025-06-19  \n",
      "1 2025-06-19  \n",
      "2 2025-06-19  \n",
      "3 2025-06-19  \n",
      "4 2025-06-19  \n",
      "The date format has been updated and saved back to the same file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(r'E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File\\19.csv')\n",
    "\n",
    "# Check the data type of 'TradeDate'\n",
    "print(\"Data type of 'TradeDate':\", df['TradeDate'].dtype)\n",
    "\n",
    "# If 'TradeDate' is not a string, convert it to string first\n",
    "if not pd.api.types.is_string_dtype(df['TradeDate']):\n",
    "    df['TradeDate'] = df['TradeDate'].astype(str)\n",
    "\n",
    "# Now convert 'TradeDate' to datetime format\n",
    "try:\n",
    "    df['TradeDate'] = pd.to_datetime(df['TradeDate'].str.replace('/', '-'), format='%d-%m-%Y')\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Display the updated DataFrame (optional, you can remove this if not needed)\n",
    "print(\"Updated DataFrame:\\n\", df.head())\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV fil\n",
    "df.to_csv(r'E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\Current Date File\\19.csv', index=False)\n",
    "\n",
    "print(\"The date format has been updated and saved back to the same file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b6bbd2-ce7d-4fb6-9de3-678a80766131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\CLUB\\19.csv\n",
      "Merged: E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\CLUB\\25_ClubADP_18.csv\n",
      "All CSV files have been merged into 'E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\CLUB\\25_ClubADP_19.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# Path to the main folder\n",
    "main_folder_path = r'E:\\Back-Up Files\\Data Team\\2024-2025\\ADP\\CLUB'  # Use raw string literal to handle backslashes\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame() \n",
    "\n",
    "# Function to recursively search for CSV files and merge them\n",
    "def merge_csv_files(directory):\n",
    "    global merged_df\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV file (case insensitive)\n",
    "            if file.lower().endswith('.csv'):\n",
    "                # Construct the full path to the CSV file\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    if not df.empty:  # Check if DataFrame is not empty\n",
    "                        # Append the DataFrame to the merged DataFrame\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "                        print(f'Merged: {file_path}')  # Optional: print each file being merged\n",
    "                    else:\n",
    "                        print(f'Skipped empty file: {file_path}')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f'Skipped file with empty data: {file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing file {file_path}: {e}') \n",
    "\n",
    "# Call the function to start merging CSV files\n",
    "merge_csv_files(main_folder_path) \n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_file_path = os.path.join(main_folder_path, '25_ClubADP_19.csv')\n",
    "merged_df.to_csv(output_file_path, index=False) \n",
    "\n",
    "print(f\"All CSV files have been merged into '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b464171-55f7-41e7-95d7-eab20527ba86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
